{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+Qoj5V/7APWfPrX5yzdPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditichak22/ml-logistic-regression/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: https://drive.google.com/file/d/19SBv8qSbSA2IvPjmyEEPRED0giBTj9kb/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "NqYqjmemGWD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWk1zNbez8a_",
        "outputId": "54574326-9a35-4ec2-8507-df14065cdca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def prepareData(datafile):\n",
        "  # data = pd.read_csv(datafile, index_col=False, names=[\"y\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\", \"x21\"])\n",
        "  data = pd.read_csv(datafile, header = None).values\n",
        "  data[:,0][data[:,0] == 0] = -1\n",
        "  X = data[:, 1:22]\n",
        "  y = data[:, 0:1]\n",
        "  \n",
        "  # m = no. of training samples, n = no. of features\n",
        "  m,n = X.shape\n",
        "  y = y.reshape(m,1)\n",
        "\n",
        "  return data, X, y\n",
        "\n",
        "# data, X_train, Y_train = prepareData(\"/content/drive/MyDrive/park_train.data\")\n",
        "# Y_train"
      ],
      "metadata": {
        "id": "2gQHC49f0mAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data, X_train, Y_train = prepareData(\"/content/drive/MyDrive/park_train.data\")\n",
        "\n",
        "init_parameters = {} \n",
        "init_parameters[\"weight\"] = np.zeros(X_train.shape[1])\n",
        "init_parameters[\"bias\"] = 0\n",
        "\n",
        "def sigmoid(input):    \n",
        "    output = 1 / (1 + np.exp(-input))\n",
        "    return output\n",
        "\n",
        "def optimize(x, y, learning_rate,iterations,parameters): \n",
        "\n",
        "    size = x.shape[0]\n",
        "    weight = parameters[\"weight\"] \n",
        "    bias = parameters[\"bias\"]\n",
        "    for i in range(iterations): \n",
        "            sigma = sigmoid(np.dot(x, weight) + bias)\n",
        "            loss = -1/size * np.sum(y * np.log(sigma)) + (1 - y) * np.log(1-sigma)\n",
        "            dW = 1/size * np.dot(x.T, (sigma - y))\n",
        "            db = 1/size * np.sum(sigma - y)\n",
        "            weight -= learning_rate * dW\n",
        "            bias -= learning_rate * db \n",
        "        \n",
        "    parameters[\"weight\"] = weight\n",
        "    parameters[\"bias\"] = bias\n",
        "    return parameters    \n",
        "\n",
        "def train(x, y, learning_rate,iterations):\n",
        "    parameters_out = optimize(x, y, learning_rate, iterations ,init_parameters)\n",
        "    return parameters_out\n",
        "\n",
        "parameters_out = train(X_train, Y_train, learning_rate = 0.02, iterations = 500)\n",
        "parameters_out\n",
        "\n"
      ],
      "metadata": {
        "id": "p0HcMe_fuLef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqBOLy6MyQlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefbf868-b153-456b-a3f6-083b061b5a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.001\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.01\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.1\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "ACCURACY ON TRAINING SET  78.2051282051282\n",
            "ACCURACY ON TEST SET  72.88135593220339\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import scipy\n",
        "from scipy.special import expit, logit\n",
        "\n",
        "def normalize(X):    \n",
        "    M,N = X.shape    \n",
        "    mean_ = X.mean(axis =0)\n",
        "    std_ = np.std(X)\n",
        "    X_scaled = (X-mean_)/std_   \n",
        "    return mean_, std_, X_scaled\n",
        "\n",
        "def probabilities(W, bias, X):\n",
        "    # print(\"fsdfs\")\n",
        "    # print(W)\n",
        "    functional_margin = np.dot(X,W) + bias\n",
        "    # print(\"here\")\n",
        "    # print(np.dot(X,W))\n",
        "    e =  scipy.special.expit(functional_margin)\n",
        "    P_x_y_1 = (e/(1+e))\n",
        "    P_x_y_m1 = (1/(1+e))\n",
        "    return P_x_y_1, P_x_y_m1, functional_margin\n",
        "\n",
        "def gradients(W, X, bias, Y):\n",
        "    M,N = X.shape\n",
        "    P_x_y_1, P_x_y_m1, functional_margin = probabilities(W, bias, X)\n",
        "    G_b = ((0.5*(Y+1)) - P_x_y_1).sum()\n",
        "    # print(\"DW!!\",-P_x_y_1)\n",
        "    G_w = np.sum(X*((0.5*(Y+1))-P_x_y_1), axis=0).reshape(N,1)\n",
        "    likelihood = np.sum( (0.5*(Y+1)*functional_margin) - np.log10(1 + scipy.special.expit(functional_margin)), axis=0)\n",
        "    # print(\"likelihood\", likelihood)\n",
        "    return (G_b, G_w, likelihood)\n",
        "\n",
        "def sigmoid(input):    \n",
        "    output = 1 / (1 + np.exp(-input))\n",
        "    return output  \n",
        "\n",
        "def logistic_train(X, Y, alpha):\n",
        "    M, N = X.shape\n",
        "    W = np.ones(N).reshape(N,1)*(0.25)\n",
        "    bias = 0.75\n",
        "    iterations = 0\n",
        "    print('PRINTING ACCURACY AFTER EACH ITERATION ')\n",
        "    G_b, G_w, likelihood = gradients(W, X, bias, Y)\n",
        "    current_likelihood = previous_likelihood = likelihood\n",
        "    max_iterations = 500\n",
        "    while iterations <  max_iterations: \n",
        "        # step = 2.0/(2.0 + iterations)\n",
        "        step = alpha\n",
        "        previous_likelihood = current_likelihood\n",
        "        W = W + step * G_w\n",
        "        bias = bias + step * G_b\n",
        "        iterations = iterations + 1\n",
        "        (G_b, G_w, current_likelihood) = gradients(W, X, bias, Y)\n",
        "        # print(iterations, G_b, accuracy(X, Y, W, bias), (current_likelihood - previous_likelihood), current_likelihood, previous_likelihood)\n",
        "        # if iterations%10000 == 0:\n",
        "        #     print(iterations, G_b, accuracy(X, Y, W, bias), (current_likelihood - previous_likelihood), current_likelihood, previous_likelihood)\n",
        "\n",
        "        if abs(current_likelihood-previous_likelihood) < 1e-7:\n",
        "            break\n",
        "        # mj = mj - 1\n",
        "        #print(G_b, accuracy(X, Y, W, bias), current_likelihood-previous_likelihood, current_likelihood, previous_likelihood)\n",
        "        \n",
        "    return (W, bias, iterations)\n",
        "\n",
        "def accuracy(X, Y, W, bias):\n",
        "    M,N = X.shape\n",
        "    Y_pred = np.dot(X, W) + bias\n",
        "    Y_pred[Y_pred>=0] = 1\n",
        "    Y_pred[Y_pred<0] = -1\n",
        "    misclassifications =  np.sum(abs(Y-Y_pred))/2\n",
        "    return (1- misclassifications/M)*100\n",
        "\n",
        "def logistic_validate(X_train, Y_train, X_val, Y_val):\n",
        "    best_W = best_bias = best_alpha = None\n",
        "    best_accuracy = 0\n",
        "    for i in range(-5, 0):\n",
        "        print('------------------------------------------------------------')\n",
        "        alpha = 10**i\n",
        "        print('VALIDATION FOR alpha ', alpha)\n",
        "        (W, bias, iterations) = logistic_train(X_train, Y_train, alpha)\n",
        "        training_accuracy = accuracy(X_train, Y_train, W, bias)  \n",
        "        current_accuracy = accuracy(X_val, Y_val, W, bias)\n",
        "        test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "        print('------------------------------------------------------------')\n",
        "        print('------------------------------------------------------------')\n",
        "        print('TRAINING ACCURACY ', training_accuracy)\n",
        "        print('VALIDATION ACCURACY ', current_accuracy)            \n",
        "        print('TEST ACCURACY ', test_accuracy)\n",
        "        print('------------------------------------------------------------')\n",
        "        print('------------------------------------------------------------')\n",
        "        if current_accuracy > best_accuracy :\n",
        "            best_accuracy = current_accuracy\n",
        "            best_W = W\n",
        "            best_bias = bias     \n",
        "            best_alpha = alpha\n",
        "        \n",
        "        print('------------------------------------------------------------')\n",
        "        \n",
        "    return (best_W, best_bias, best_alpha)\n",
        "\n",
        "# (X_train, Y_train) = prepare_data(data_train)\n",
        "data, X_train, Y_train = prepareData(\"/content/drive/MyDrive/park_train.data\")\n",
        "# X_scaled_train, X_mean, X_sd = normalize(X_train)\n",
        "# (X_val, Y_val) = prepare_data(data_val)\n",
        "data, X_val, Y_val = prepareData(\"/content/drive/MyDrive/park_validation.data\")\n",
        "# #X_val = rescale(X_val, X_mean, X_sd)\n",
        "data, X_test, Y_test = prepareData(\"/content/drive/MyDrive/park_test.data\")\n",
        "# #X_test = rescale(X_test, X_mean, X_sd)\n",
        "\n",
        "W, bias, alpha = logistic_validate(X_train, Y_train, X_val, Y_val)\n",
        "training_accuracy = accuracy(X_train, Y_train, W, bias)\n",
        "print('ACCURACY ON TRAINING SET ', training_accuracy)\n",
        "test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "print('ACCURACY ON TEST SET ', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the input data is prfectly linearly separable, the logistic regression model can no longer be trained because the weight would not converge as optimal weight would be infinite. \n",
        "\n",
        "This problem can be solved by introducing penalization of weights or defining a prior probability distribution of weights. "
      ],
      "metadata": {
        "id": "NEOqHi_t-_K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probabilities(W, bias, X):\n",
        "    # print(\"fsdfs\")\n",
        "    # print(W)\n",
        "    functional_margin = np.dot(X,W) + bias\n",
        "    # print(\"here\")\n",
        "    # print(np.dot(X,W))\n",
        "    e =  scipy.special.expit(functional_margin)\n",
        "    P_x_y_1 = (e/(1+e))\n",
        "    P_x_y_m1 = (1/(1+e))\n",
        "    return P_x_y_1, P_x_y_m1, functional_margin\n",
        "\n",
        "def gradients(W, X, bias, Y, lamb):\n",
        "    M,N = X.shape\n",
        "    P_x_y_1, P_x_y_m1, functional_margin = probabilities(W, bias, X)\n",
        "    G_b = ((0.5*(Y+1))-P_x_y_1).sum()\n",
        "    G_w = np.sum(X*((0.5*(Y+1))-P_x_y_1), axis=0).reshape(N,1) - lamb*W\n",
        "    likelihood = np.sum( 0.5*(Y+1)*functional_margin - np.log(1 + scipy.special.expit(functional_margin)), axis=0) - (lamb)*np.sum(W**2,axis=0)\n",
        "    return (G_b, G_w, likelihood)\n",
        "\n",
        "def calculate_loss(W, Y, X, bias):\n",
        "    return np.sum((0.5)*(Y+1)*(np.dot(X, W)+bias) - np.log(1 + scipy.special.expit(np.dot(X,W) + bias)))\n",
        "\n",
        "def logistic_train(X, Y, alpha, lamb):\n",
        "    M, N = X.shape\n",
        "    W = np.ones(N).reshape(N,1)*(0.5)\n",
        "    bias = 0.5\n",
        "    iterations = 0\n",
        "    #print('PRINTING ACCURACY AFTER EACH ITERATION ')\n",
        "    (G_b, G_w, likelihood) = gradients(W, X, bias, Y, lamb)\n",
        "    current_likelihood = previous_likelihood = likelihood\n",
        "    max_iterations = 500\n",
        "    while iterations <  max_iterations:\n",
        "        previous_likelihood = current_likelihood\n",
        "        W = W + alpha * G_w\n",
        "        bias = bias + alpha * G_b\n",
        "        iterations = iterations + 1\n",
        "        (G_b, G_w, current_likelihood) = gradients(W, X, bias, Y, lamb)\n",
        "        # if iterations%1000 == 0:\n",
        "        #     print(iterations, G_b, accuracy(X, Y, W, bias), current_likelihood-previous_likelihood, current_likelihood, previous_likelihood)\n",
        "        if abs(current_likelihood-previous_likelihood) < 1e-4:\n",
        "            break\n",
        "        #print(G_b, accuracy(X, Y, W, bias), current_likelihood-previous_likelihood)\n",
        "        \n",
        "    return (W, bias, iterations)\n",
        "\n",
        "def accuracy(X, Y, W, bias):\n",
        "    M,N = X.shape\n",
        "    Y_pred = np.dot(X, W) + bias\n",
        "    Y_pred[Y_pred>0] = 1\n",
        "    Y_pred[Y_pred<0] = -1\n",
        "    misclassifications =  np.sum(abs(Y-Y_pred))/2\n",
        "    return (1- misclassifications/M)*100\n",
        "\n",
        "def logistic_validate(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "    best_W = best_bias = best_alpha = best_lamb = None\n",
        "    best_accuracy = 0\n",
        "    for i in range(-6, -3):        \n",
        "        alpha = 10**i\n",
        "        for j in range(-4,5):\n",
        "            lamb = 10**j\n",
        "            print('------------------------------------------------------------')\n",
        "            print('VALIDATION FOR alpha ', alpha, ', lambda ', lamb)\n",
        "            (W, bias, iterations) = logistic_train(X_train, Y_train, alpha, lamb)\n",
        "            training_accuracy = accuracy(X_train, Y_train, W, bias)  \n",
        "            current_accuracy = accuracy(X_val, Y_val, W, bias)\n",
        "            test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "            print('------------------------------------------------------------')\n",
        "            print('------------------------------------------------------------')\n",
        "            print('TRAINING ACCURACY ', training_accuracy)\n",
        "            print('VALIDATION ACCURACY ', current_accuracy)            \n",
        "            print('TEST ACCURACY ', test_accuracy)\n",
        "            print('------------------------------------------------------------')\n",
        "            print('------------------------------------------------------------')\n",
        "            if current_accuracy > best_accuracy :\n",
        "                best_accuracy = current_accuracy\n",
        "                best_W = W\n",
        "                best_bias = bias     \n",
        "                best_alpha = alpha\n",
        "                best_lamb = lamb\n",
        "            print('------------------------------------------------------------')\n",
        "        \n",
        "        \n",
        "    return (best_W, best_bias, best_alpha, best_lamb)\n",
        "\n",
        "data, X_train, Y_train = prepareData(\"/content/drive/MyDrive/park_train.data\")\n",
        "data, X_val, Y_val = prepareData(\"/content/drive/MyDrive/park_validation.data\")\n",
        "data, X_test, Y_test = prepareData(\"/content/drive/MyDrive/park_test.data\")\n",
        "\n",
        "(W, bias, alpha, lamb) = logistic_validate(X_train, Y_train, X_val, Y_val, X_test, Y_test)\n",
        "training_accuracy = accuracy(X_train, Y_train, W, bias)\n",
        "print(\"Weights\", W)\n",
        "print('ACCURACY ON TRAINING SET ', training_accuracy)\n",
        "test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "print('ACCURACY ON TEST SET ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPz66SYV_6di",
        "outputId": "7b35b28f-d464-44eb-a3a5-c025634a44a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  0.0001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  0.001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  0.01\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  0.1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  10\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  100\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  1000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-06 , lambda  10000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.0001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.01\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  10\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  100\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  10000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  0.0001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  0.001\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  0.01\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  0.1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  1\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  10\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  100\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  1000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  0.0001 , lambda  10000\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "Weights [[2.01378394]\n",
            " [2.24929968]\n",
            " [1.5355722 ]\n",
            " [0.50008168]\n",
            " [0.50000059]\n",
            " [0.50004493]\n",
            " [0.50004601]\n",
            " [0.50013483]\n",
            " [0.50045963]\n",
            " [0.50433072]\n",
            " [0.50024455]\n",
            " [0.50027891]\n",
            " [0.5003624 ]\n",
            " [0.5007337 ]\n",
            " [0.5003424 ]\n",
            " [0.71488772]\n",
            " [0.50597362]\n",
            " [0.50801503]\n",
            " [0.44693129]\n",
            " [0.50303204]\n",
            " [0.52797107]]\n",
            "ACCURACY ON TRAINING SET  78.2051282051282\n",
            "ACCURACY ON TEST SET  72.88135593220339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probabilities(W, bias, X):\n",
        "    functional_margin = np.dot(X,W) + bias\n",
        "    e = scipy.special.expit(functional_margin)\n",
        "    P_x_y_1 = (e/(1+e))\n",
        "    P_x_y_m1 = (1/(1+e))\n",
        "    return (P_x_y_1, P_x_y_m1, functional_margin)\n",
        "\n",
        "def gradients(W, X, bias, Y, lamb):\n",
        "    M,N = X.shape\n",
        "    P_x_y_1, P_x_y_m1, functional_margin = probabilities(W, bias, X)\n",
        "    G_b = ((0.5*(Y+1))-P_x_y_1).sum()\n",
        "    norm_derivative = W\n",
        "    norm_derivative[norm_derivative<0] = -1\n",
        "    norm_derivative[norm_derivative>=0] = 1\n",
        "    G_w = np.sum(X*((0.5*(Y+1))-P_x_y_1), axis=0).reshape(N,1) - lamb*norm_derivative\n",
        "    likelihood = np.sum( 0.5*(Y+1)*functional_margin - np.log(1 + scipy.special.expit(functional_margin)), axis=0) - lamb*np.sum(abs(W), axis=0)\n",
        "    return G_b, G_w, likelihood\n",
        "\n",
        "def logistic_train(X, Y, alpha, lamb):\n",
        "    M, N = X.shape\n",
        "    W = np.ones(N).reshape(N,1)*(0.25)\n",
        "    bias = 0.75\n",
        "    iterations = 0\n",
        "    print('PRINTING ACCURACY AFTER EACH ITERATION ')\n",
        "    (G_b, G_w, likelihood) = gradients(W, X, bias, Y, lamb)\n",
        "    current_likelihood = previous_likelihood = likelihood\n",
        "    max_iterations = 500\n",
        "    while iterations <  max_iterations:\n",
        "        previous_likelihood = current_likelihood\n",
        "        W = W + alpha * G_w\n",
        "        bias = bias + alpha * G_b\n",
        "        iterations = iterations + 1\n",
        "        (G_b, G_w, current_likelihood) = gradients(W, X, bias, Y, lamb)\n",
        "        if iterations%10000 == 0:\n",
        "            print(iterations, G_b, accuracy(X, Y, W, bias), current_likelihood-previous_likelihood, current_likelihood, previous_likelihood)\n",
        "        \n",
        "        if abs(current_likelihood-previous_likelihood) < 1e-7:\n",
        "            break\n",
        "        \n",
        "        #print(G_b, accuracy(X, Y, W, bias), current_likelihood-previous_likelihood, current_likelihood, previous_likelihood)\n",
        "        \n",
        "    return (W, bias, iterations)\n",
        "\n",
        "def accuracy(X, Y, W, bias):\n",
        "    M,N = X.shape\n",
        "    Y_pred = np.dot(X, W) + bias\n",
        "    Y_pred[Y_pred>0] = 1\n",
        "    Y_pred[Y_pred<0] = -1\n",
        "    misclassifications =  np.sum(abs(Y-Y_pred))/2\n",
        "    return (1- misclassifications/M)*100\n",
        "\n",
        "def logistic_validate(X_train, Y_train, X_val, Y_val):\n",
        "    best_W = best_bias = best_alpha = best_lamb = None\n",
        "    best_accuracy = 0\n",
        "    for i in range(-5, -4):\n",
        "        print('------------------------------------------------------------')\n",
        "        alpha = 10**i\n",
        "        for j in range(-6,5):\n",
        "            lamb = 10**j\n",
        "            print('VALIDATION FOR alpha ', alpha, ', lambda ', lamb)\n",
        "            (W, bias, iterations) = logistic_train(X_train, Y_train, alpha, lamb)\n",
        "            training_accuracy = accuracy(X_train, Y_train, W, bias)  \n",
        "            current_accuracy = accuracy(X_val, Y_val, W, bias)\n",
        "            test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "            print('------------------------------------------------------------')\n",
        "            print('------------------------------------------------------------')\n",
        "            print('TRAINING ACCURACY ', training_accuracy)\n",
        "            print('VALIDATION ACCURACY ', current_accuracy)            \n",
        "            print('TEST ACCURACY ', test_accuracy)\n",
        "            print('------------------------------------------------------------')\n",
        "            print('------------------------------------------------------------')\n",
        "            if current_accuracy > best_accuracy :\n",
        "                best_accuracy = current_accuracy\n",
        "                best_W = W\n",
        "                best_bias = bias     \n",
        "                best_alpha = alpha\n",
        "                best_lamb = lamb\n",
        "        \n",
        "        print('------------------------------------------------------------')\n",
        "        \n",
        "    return (best_W, best_bias, best_alpha, best_lamb)\n",
        "\n",
        "\n",
        "data, X_train, Y_train = prepareData(\"/content/drive/MyDrive/park_train.data\")\n",
        "data, X_val, Y_val = prepareData(\"/content/drive/MyDrive/park_validation.data\")\n",
        "data, X_test, Y_test = prepareData(\"/content/drive/MyDrive/park_test.data\")\n",
        "\n",
        "(W, bias, alpha, lamb) = logistic_validate(X_train, Y_train, X_val, Y_val)\n",
        "print(\"Weights\", W)\n",
        "training_accuracy = accuracy(X_train, Y_train, W, bias)\n",
        "print('ACCURACY ON TRAINING SET ', training_accuracy)\n",
        "val_accuracy = accuracy(X_val, Y_val, W, bias)\n",
        "print('ACCURACY ON VALIDATION SET ', val_accuracy)\n",
        "test_accuracy = accuracy(X_test, Y_test, W, bias)\n",
        "print('ACCURACY ON TEST SET ', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM72rZ23BE5x",
        "outputId": "f47c84f6-2da8-4d3d-fe7e-4c3eec917e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1e-06\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1e-05\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.0001\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.001\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.01\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  0.1\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  10\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  100\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  1000\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "VALIDATION FOR alpha  1e-05 , lambda  10000\n",
            "PRINTING ACCURACY AFTER EACH ITERATION \n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "TRAINING ACCURACY  78.2051282051282\n",
            "VALIDATION ACCURACY  74.13793103448276\n",
            "TEST ACCURACY  72.88135593220339\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "------------------------------------------------------------\n",
            "Weights [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "ACCURACY ON TRAINING SET  78.2051282051282\n",
            "ACCURACY ON VALIDATION SET  74.13793103448276\n",
            "ACCURACY ON TEST SET  72.88135593220339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the weights get smaller, L1 updates the weights by the same lambda but L2 updates by Lambda * W. A net change in W increases L1 rather than L2 as the weights get smaller. So L produces sparser weights than L2. "
      ],
      "metadata": {
        "id": "UQqvICxZCvDc"
      }
    }
  ]
}